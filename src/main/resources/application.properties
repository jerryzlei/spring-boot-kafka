project.name=spring-boot-kafka
spring.profiles.active=@profile-active@
spring.application.name=kafka
#spring.application.name=${project.name}
server.port=8080

log.path=/usr/local/project/logs/${spring.application.name}


swagger.base-package=com.qudian
swagger.title=kafka
swagger.version=1.0.0
swagger.base-path=/**
swagger.exclude-path=/ops/**,/error
swagger.contact.name=zhengfei
swagger.contact.email=zhengfe_i@163.com
swagger.contact.url=www.baidu.com


#============== kafka ===================
#kafka.consumer.zookeeper.connect=hadoop1.xqcx.com:2181,hadoop2.xqcx.com:2181,hadoop3.xqcx.com:2181
kafka.consumer.zookeeper.connect=10.65.3.5:2181
kafka.consumer.servers=10.65.3.5:9092
#kafka.consumer.servers=hadoop1.xqcx.com:9092,hadoop2.xqcx.com:9092,hadoop3.xqcx.com:9092
#如果此值设置为true，consumer会周期性的把当前消费的offset值保存到zookeeper。当consumer失败重启之后将会使用此值作为新开始消费的值
kafka.consumer.enable.auto.commit=false
#ZooKeeper session 超时时间。如果在此时间内server没有向zookeeper发送心跳，zookeeper就会认为此节点已挂掉。 此值太低导致节点容易被标记死亡；若太高，.会导致太迟发现节点死亡。
#kafka.consumer.session.timeout=13000
kafka.consumer.session.timeout=30000
#Consumer提交offset值到zookeeper的周期。
kafka.consumer.auto.commit.interval=100
#kafka.consumer.auto.commit.interval=100
#如果卡夫卡没有初始偏移量，或者服务器上当前的偏移量不存在，该怎么处理，latest 最新的
kafka.consumer.auto.offset.reset=latest
#并发数
kafka.consumer.concurrency=10
#每次只拉一条
kafka.consumer.max-poll-records=1


kafka.producer.servers=10.65.3.5:9092
#kafka.producer.servers=hadoop1.xqcx.com:9092,hadoop2.xqcx.com:9092,hadoop3.xqcx.com:9092
kafka.producer.retries=0
kafka.producer.batch.size=4096
kafka.producer.linger=1
#缓冲区大小
kafka.producer.buffer.memory=40960

kafka_topic_example = icmp_ly_black_task